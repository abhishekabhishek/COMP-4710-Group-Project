# -*- coding: utf-8 -*-
#!/home/abhi/anaconda3/envs/dev1/bin/python

"""Main program to train and test the HMM implementation with the aruba1
test and train datasets."""

# Preamble setup and module initialization

# Standary library and third-party module documentations
# sys - https://docs.python.org/3.6/library/sys.html
# logging - https://docs.python.org/3.6/library/logging.html
# os.path - https://docs.python.org/3.6/library/os.path.html
# configparser - https://docs.python.org/3.6/library/configparser.html
# datetime - https://docs.python.org/3.6/library/datetime.html

# Prevent the python interpreter to make .pyc files
import sys
sys.dont_write_bytecode = True

# Capture all warnings generated by the program and log them into a logger
import logging
logging.captureWarnings(True)

# Paths for storing logs and test results
from os import path

# Reader for the configuration file
from configparser import ConfigParser
from configparser import ExtendedInterpolation

# Module for manipulating dates and times
from datetime import datetime
import time

# Import the modules implemented to run the program

# Logging the output from the program for testing
from logger import Logger

# Loading the datasets, formatting and constructing dataframes to perform
# data analysis : training and testing
from dataloader import DataLoader

# Import the module with the implementation of the HMM using hmmlearn
from hmm import HMM

# Module for post-processing the output after training and testing the 
# outputs
from postprocessor import PostProcessor

# Module from data analysis libraries
import numpy as np

# Module for easy terminal visualization of the loops
from tqdm import tqdm

# Print iterations progress
def print_progress(iteration, total, prefix='', suffix='', decimals=1, bar_length=100):
  
    """
    Call in a loop to create terminal progress bar
    @params:
        iteration   - Required  : current iteration (Int)
        total       - Required  : total iterations (Int)
        prefix      - Optional  : prefix string (Str)
        suffix      - Optional  : suffix string (Str)
        decimals    - Optional  : positive number of decimals in percent complete (Int)
        bar_length  - Optional  : character length of bar (Int)
    """
    str_format = "{0:." + str(decimals) + "f}"
    percents = str_format.format(100 * (iteration / float(total)))
    filled_length = int(round(bar_length * iteration / float(total)))
    bar = '>' * filled_length + '-' * (bar_length - filled_length)

    sys.stdout.write('\r%s |%s| %s%s %s' % (prefix, bar, percents, '%', suffix)),

    if iteration == total:
        sys.stdout.write('\n')
        
    sys.stdout.flush()

# Creating the scope for the top-level code execution

# Steps :
  # 1. Read in the configuration file for FS paths for data files and output
  #    log files.
  # 2. Initialize the logging mechanism to log the output of the program.
  # 3. Construct the datasets from the training and testing datafiles.
  # 4. Extract the features from the training and testing dataframes necessary
  #    to train the HMM model.
  # 5. Initialize the model and fit using the observation dataset.
  # 5. Test the HMM using the test data files.
  # 6. Process the output of the tests to visualize the accuracy of the models

if __name__ == '__main__':
  
  #----------------------------------------------------------------------------
  
  # FS path to the configuration file
  config_file_path = path.join(str(path.expanduser("~")),
                               'dev1/step_project_3/implementations/MMPP/HMM/config/hmm.cfg')
  
  # Initialize the configuration parser and read in the configuration file
  config = ConfigParser(allow_no_value=True, 
                        interpolation=ExtendedInterpolation())
  
  config.read(config_file_path)
  #----------------------------------------------------------------------------
  
  # Timestamp string to timestamp the log and test files
  time_str = datetime.now().strftime("-%Y-%m-%d-%H:%M:%S")
  
  #----------------------------------------------------------------------------
  
  # Initialize the logging mechanism
  log_file_name = 'test-' + config.get('TESTING', 'test_num') + time_str
  log_file_path = path.join(str(path.expanduser("~")), 
                            config.get('LOGGING', 'logs_folder') + log_file_name)
  
  # Redirect the standard output
  sys.stdout = Logger(filename=log_file_path)
  
  #----------------------------------------------------------------------------
  
  # FS path parameters to be used for reading data files and constructing the
  # dataframes for the datasets
  
  train_raw_data_path = path.join(str(path.expanduser("~")), 
                                  config.get('DATAINPUT', 'train_raw_data_path'))
  test_raw_data_path = path.join(str(path.expanduser("~")), 
                                 config.get('DATAINPUT', 'test_raw_data_path'))
  
  train_fmt_data_path = path.join(str(path.expanduser("~")), 
                                  config.get('DATAINPUT', 'train_fmt_data_path'))
  test_fmt_data_path = path.join(str(path.expanduser("~")), 
                                 config.get('DATAINPUT', 'test_fmt_data_path'))
  
  # Initialize the dictionary for the columns to be read
  columns_dict = {}
  
  # Read in the values from the configuration file and add to the dictionary
  for key in config['DATAINPUTCOLUMNS']:
    columns_dict[key] = config.getint('DATAINPUTCOLUMNS', key)
  
  # Check to see if the formatted csv files exist, if not call the raw reader
  # method to read in the raw, else load the dataframes from the formatted files
  
  if path.exists(train_fmt_data_path) and path.exists(test_fmt_data_path):
    train_df, test_df = DataLoader.load_formatted(train_fmt_data_path,
                                                   test_fmt_data_path)
  else:
    train_df, test_df = DataLoader.load_raw(train_raw_data_path, 
                                            train_fmt_data_path,
                                            test_raw_data_path,
                                            test_fmt_data_path,
                                            columns_dict)
    
  #----------------------------------------------------------------------------
  
  # Path to the saved model directory
  model_data_path = path.join(str(path.expanduser("~")),
                                  config.get('DATAOUTPUT', 'model_data_path'))
  
  # Using the naive approach to extract the features in form of observations
  raw_observations = train_df['sensor_id']
  unique_motion_ids, unique_door_ids = DataLoader.get_unique_sensors(raw_observations.values,
                                                                     model_data_path, False)
  
  sensor_map, inverse_sensor_map = DataLoader.build_maps(unique_motion_ids,
                                                         unique_door_ids)
  
  data_shape = (-1,30)
  hmm_observations = raw_observations.map(sensor_map).values
  
  # Make the dataset divisible by the desired sequence lengths
  hmm_observations = hmm_observations[:int(np.floor(len(hmm_observations)/data_shape[1])*data_shape[1])].reshape(data_shape)

  #----------------------------------------------------------------------------
  
  # Train the models with the fewest possible hyper-parameters to allow
  # good inference from the training dataset
  min_hidden_states = 60
  max_hidden_states = 60
  max_iterations = 50
  covariance = 'tied'
  tolerance = 0.000005
  
  num_hidden_states_list = [i for i in range(min_hidden_states, max_hidden_states+1)]
  
  # Path to the saved model directory
  model_save_path = path.join(str(path.expanduser("~")),
                                  config.get('DATAOUTPUT', 'model_save_path'))
  
  hmm_module = HMM()
  trained_models_viterbi, trained_models_map = hmm_module.fit_data(model_index=0,
                                                                   input_dataset=hmm_observations,
                                                                   num_components_list=num_hidden_states_list,
                                                                   n_iterations=max_iterations,
                                                                   model_save_dir=model_save_path,
                                                                   covariance_class=covariance,
                                                                   conv_tol=tolerance,
                                                                   input_shape=data_shape)
  
  #----------------------------------------------------------------------------
  
  # Test the trained HMM models on the test dataset
  
  # Build the maps for the test dataset
  raw_test_observations = test_df['sensor_id']
  test_motion_ids, test_door_ids = DataLoader.get_unique_sensors(raw_test_observations.values,
                                                                     model_data_path, True)
  
  
  test_sensor_map, inverse_test_sensor_map = DataLoader.build_test_maps(sensor_map,
                                                                        inverse_sensor_map,
                                                                        test_motion_ids,
                                                                        test_door_ids)
  
  test_observations = raw_test_observations.map(test_sensor_map).values
  
  # Make the dataset divisible by the desired sequence lengths
  test_observations = test_observations[:int(np.floor(len(test_observations)/data_shape[1])*data_shape[1])].reshape(data_shape)
  
  # First approach for testing - single observations one by one
  # Don't think this will be very robust to anomalies

  model_viterbi_scores = []
  
  # Test all the different models trained using the Viterbi algorithm
  for model in trained_models_viterbi:
    
    print('Scoring the test dataset using the model: \n' + str(model))
    single_observation_scores = []
    
    max_iter = np.floor(len(test_observations)/data_shape[1])
    
    # Initialize the progress bar to visualize the scoring loop
    pbar = tqdm(total=max_iter)
    
    for observation in test_observations:
      
      observation_array = np.array([observation]).reshape(data_shape)
      single_observation_scores.append(model.score(observation_array))
      
      # Update the progess bar
      pbar.update(1)
      
    model_viterbi_scores.append(single_observation_scores)
    
  # Test all the different models trained using the MAP algorithm
  
  '''
  model_map_scores = []
  
  for model in trained_models_map:
    
    single_observation_scores = []
    
    for observation in test_observations:
      observation_array = np.array([observation]).reshape(data_shape)
      single_observation_scores.append(model.score(observation_array))
      
    model_map_scores.append(single_observation_scores)
  
  
  print(model_viterbi_scores[0])  
  '''
      
  #-----------------------------------------------------------------------------
 
  # Display the results from thhe first test using only the single observations
 
  #test_timestamps = test_df['timestamp'].values
  print(model_viterbi_scores[0])
  
  # PLot the most basic results
  PostProcessor.plot_basic(model_viterbi_scores[0], data_shape[1])
    
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  